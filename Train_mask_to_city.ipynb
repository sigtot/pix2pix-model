{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    },
    "colab": {
      "name": "Copy of mask_to_city.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPZjipS7kUoK",
        "colab_type": "code",
        "outputId": "9de7964a-0947-4091-c192-64438c62efc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "! git clone https://github.com/sigtot/unet-auto unet"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'unet'...\n",
            "remote: Enumerating objects: 441, done.\u001b[K\n",
            "remote: Counting objects: 100% (441/441), done.\u001b[K\n",
            "remote: Compressing objects: 100% (233/233), done.\u001b[K\n",
            "remote: Total 441 (delta 246), reused 393 (delta 200), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (441/441), 48.78 MiB | 31.52 MiB/s, done.\n",
            "Resolving deltas: 100% (246/246), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_VzgFzs37xk",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8v8t4c1_VKN",
        "colab_type": "code",
        "outputId": "b1b6cc6e-fd52-46ad-ddb0-99f69f854c76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "! git -C unet checkout master"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already on 'master'\n",
            "Your branch is up to date with 'origin/master'.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNPmdDPHn8SF",
        "colab_type": "code",
        "outputId": "a76ad77f-7f06-483c-8250-7be8fe035003",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! git -C unet pull"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qx21JWORA3Lg",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81eAI7tNpIc9",
        "colab_type": "code",
        "outputId": "e6c32546-0f25-4995-b10c-0bd627d844b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "PhxokDPckLxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import os\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import Cityscapes\n",
        "from torchvision.utils import save_image\n",
        "from unet.unet import PavelNet\n",
        "from unet.unet import SigurdModel\n",
        "import datetime\n",
        "import numpy as np\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "VJiWslqnkLxo",
        "colab_type": "code",
        "outputId": "9bb64e14-58d6-473b-8a14-a2ca09125ef7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# set device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(f\"Using device {device}\")\n",
        "\n",
        "# make a folder to save output images\n",
        "if not os.path.exists('./mlp_img'):\n",
        "    os.mkdir('./mlp_img')\n",
        "    \n",
        "\n",
        "# a function used to transform numpy array to image format\n",
        "def to_img(x):\n",
        "    #x = 0.5 * (x + 1)\n",
        "    x = x.clamp(0, 1)\n",
        "    x = x.view(x.size(0), x.size(1), x.size(2), x.size(3))\n",
        "    return x\n",
        "\n",
        "#################### select your hyperparameters ############################\n",
        "num_epochs = 200\n",
        "batch_size = 1\n",
        "n_samples = 10\n",
        "\n",
        "####### define image transforms, you can have other choices, explore it! #####\n",
        "class DoubleCompose(transforms.Compose):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(DoubleCompose, self).__init__(*args, **kwargs)\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        seed = np.random.randint(2147483647)\n",
        "        random.seed(seed)\n",
        "        t_image = super(DoubleCompose, self).__call__(image)\n",
        "        random.seed(seed)\n",
        "        t_target = super(DoubleCompose, self).__call__(target)\n",
        "        return t_image, t_target\n",
        "\n",
        "transform = DoubleCompose([\n",
        "    transforms.Resize((286, 286)),\n",
        "    transforms.RandomCrop((256, 256)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# download dataset\n",
        "dataset = Cityscapes('/content/drive/My Drive/citytiny', transforms=transform, target_type='color')\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, pin_memory=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using device cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "7XSotqjIkLxw",
        "colab_type": "code",
        "outputId": "028724ea-2f81-439d-8614-604fd1278352",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = SigurdModel(lr=0.0002, betas=(0.5, 0.999), weight_decay=1e-8, disc_mult=0.5, l1_mult=100, l1_only=False)\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SigurdModel(\n",
              "  (discriminator): ArtNet(\n",
              "    (model): Sequential(\n",
              "      (0): Conv2d(6, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "      (2): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "      )\n",
              "      (3): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "      )\n",
              "      (4): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "      )\n",
              "      (5): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (generator): PavelNet(\n",
              "    (e1): EncodeModule(\n",
              "      (layers): Sequential(\n",
              "        (conv): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "        (relu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (e2): EncodeModule(\n",
              "      (layers): Sequential(\n",
              "        (conv): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (e3): EncodeModule(\n",
              "      (layers): Sequential(\n",
              "        (conv): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (e4): EncodeModule(\n",
              "      (layers): Sequential(\n",
              "        (conv): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (e5): EncodeModule(\n",
              "      (layers): Sequential(\n",
              "        (conv): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (e6): EncodeModule(\n",
              "      (layers): Sequential(\n",
              "        (conv): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (e7): EncodeModule(\n",
              "      (layers): Sequential(\n",
              "        (conv): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (e8): EncodeModule(\n",
              "      (layers): Sequential(\n",
              "        (conv): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "        (relu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (d1): DecodeModule(\n",
              "      (up): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2))\n",
              "      (layers): Sequential(\n",
              "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (do): Dropout2d(p=0.5, inplace=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (d2): DecodeModule(\n",
              "      (up): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2))\n",
              "      (layers): Sequential(\n",
              "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (do): Dropout2d(p=0.5, inplace=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (d3): DecodeModule(\n",
              "      (up): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2))\n",
              "      (layers): Sequential(\n",
              "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (do): Dropout2d(p=0.5, inplace=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (d4): DecodeModule(\n",
              "      (up): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2))\n",
              "      (layers): Sequential(\n",
              "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (d5): DecodeModule(\n",
              "      (up): ConvTranspose2d(1024, 256, kernel_size=(4, 4), stride=(2, 2))\n",
              "      (layers): Sequential(\n",
              "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (d6): DecodeModule(\n",
              "      (up): ConvTranspose2d(512, 128, kernel_size=(4, 4), stride=(2, 2))\n",
              "      (layers): Sequential(\n",
              "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (d7): DecodeModule(\n",
              "      (up): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2))\n",
              "      (layers): Sequential(\n",
              "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (out): Sequential(\n",
              "      (0): ConvTranspose2d(128, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "      (1): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (loss): MSELoss()\n",
              "  (l1loss): L1Loss()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BA904c_r5068",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_save_path = \"/content/drive/My Drive/models/model_cgan_l1_new.pt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cv3rPf3R5ruE",
        "colab_type": "code",
        "outputId": "c9de9f77-a9f7-4e2a-8597-f42c8254c0e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "refresh_model = False\n",
        "if os.path.isfile(model_save_path) and not refresh_model:\n",
        "    checkpoint = torch.load(model_save_path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    loss_G = checkpoint['loss_G']\n",
        "    loss_D = checkpoint['loss_D']\n",
        "    print(f\"Loaded {start_epoch + 1} epochs from file\")\n",
        "else:\n",
        "    start_epoch = 0\n",
        "    print(\"Starting with a fresh model\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 189 epochs from file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": false
        },
        "id": "1xATd-FxkLx4",
        "colab_type": "code",
        "outputId": "31906b86-6581-4192-e7cc-4c69bddd2cb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "for epoch in range(start_epoch, num_epochs):\n",
        "    for i, data in enumerate(dataloader):\n",
        "        if i > 10:\n",
        "            exit(0)\n",
        "        img, mask_with_alpha = data\n",
        "        mask = mask_with_alpha[:, :3, :, :]\n",
        "        img = img.to(device)\n",
        "        mask = mask.to(device)\n",
        "        #img = img.view(img.size(0), -1)\n",
        "        \n",
        "        img_pred = model.forward(mask, img)\n",
        "        loss_G, loss_D = model.backward()\n",
        "\n",
        "    # ===================user interaction========================\n",
        "    print('epoch [{}/{}], loss G:{:.4f}, loss D: {:.4f}'.format(epoch + 1, num_epochs, loss_G, loss_D))\n",
        "    if epoch % 1 == 0:\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'loss_G': loss_G,\n",
        "            'loss_D': loss_D\n",
        "            }, model_save_path)\n",
        "\n",
        "        pic = to_img(img_pred.data)\n",
        "        save_image(pic, './mlp_img/image_{}.png'.format(epoch))\n",
        "        \n",
        "        ori_pic = to_img(img.data)\n",
        "        save_image(ori_pic, './mlp_img/ori_image_{}.png'.format(epoch))\n",
        "        \n",
        "        mask_pic = to_img(mask.data)\n",
        "        save_image(mask_pic, './mlp_img/mask_image_{}.png'.format(epoch))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch [189/200], loss G:7.5662, loss D: 0.0000\n",
            "epoch [190/200], loss G:4.9392, loss D: 0.0001\n",
            "epoch [191/200], loss G:7.8371, loss D: 0.0000\n",
            "epoch [192/200], loss G:8.5910, loss D: 0.0000\n",
            "epoch [193/200], loss G:6.8394, loss D: 0.0000\n",
            "epoch [194/200], loss G:5.9928, loss D: 0.0001\n",
            "epoch [195/200], loss G:6.0210, loss D: 0.0000\n",
            "epoch [196/200], loss G:5.5521, loss D: 0.0000\n",
            "epoch [197/200], loss G:6.7824, loss D: 0.0000\n",
            "epoch [198/200], loss G:5.3400, loss D: 0.0000\n",
            "epoch [199/200], loss G:6.0071, loss D: 0.0000\n",
            "epoch [200/200], loss G:5.4111, loss D: 0.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "-MWqV5HtkLyA",
        "colab_type": "code",
        "outputId": "34b86bfe-6f4d-45b6-e969-012bd5a7fa37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "class CityScapesWithPaths(Cityscapes):\n",
        "    def __init__(self, root, split='train', mode='fine', target_type='instance',\n",
        "        transform=None, target_transform=None, transforms=None):\n",
        "        super(CityScapesWithPaths, self).__init__(root, split=split, mode=mode, target_type=target_type,transform=transform, target_transform=target_transform, transforms=transforms)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        original_tuple = super(CityScapesWithPaths, self).__getitem__(index)\n",
        "        path = self.images[index]\n",
        "        tuple_with_path = ((path,) + original_tuple)\n",
        "        return tuple_with_path\n",
        "\n",
        "batch_size = 1\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "dataset_val = CityScapesWithPaths('/content/drive/My Drive/citysmall', transform=transform, target_transform=transform, target_type='color', split=\"val\")\n",
        "num_imgs = 20\n",
        "\n",
        "if not os.path.exists('./val_img'):\n",
        "    os.mkdir('./val_img')\n",
        "\n",
        "for i, data in enumerate(dataset_val):\n",
        "    if i >= num_imgs:\n",
        "        break\n",
        "    path, img, mask_with_alpha = data\n",
        "    save_image(img, './val_img/ori_image_{}.jpg'.format(i))\n",
        "    save_image(mask_with_alpha, './val_img/mask_image_{}.png'.format(i))\n",
        "\n",
        "    mask = mask_with_alpha[:3, :, :]\n",
        "\n",
        "    mask = mask.unsqueeze(0)\n",
        "    img = img.unsqueeze(0)\n",
        "\n",
        "    img = img.to(device)\n",
        "    mask = mask.to(device)\n",
        "    \n",
        "    img_pred = model.forward(mask, img)\n",
        "\n",
        "    pic = to_img(img_pred.data)\n",
        "    save_image(img_pred, './val_img/image_{}.jpg'.format(i))\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/citysmall/leftImg8bit/val/lindau/lindau_000035_000019_leftImg8bit.png\n",
            "/content/drive/My Drive/citysmall/leftImg8bit/val/lindau/lindau_000043_000019_leftImg8bit.png\n",
            "/content/drive/My Drive/citysmall/leftImg8bit/val/lindau/lindau_000012_000019_leftImg8bit.png\n",
            "/content/drive/My Drive/citysmall/leftImg8bit/val/lindau/lindau_000052_000019_leftImg8bit.png\n",
            "/content/drive/My Drive/citysmall/leftImg8bit/val/lindau/lindau_000000_000019_leftImg8bit.png\n",
            "/content/drive/My Drive/citysmall/leftImg8bit/val/lindau/lindau_000019_000019_leftImg8bit.png\n",
            "/content/drive/My Drive/citysmall/leftImg8bit/val/lindau/lindau_000015_000019_leftImg8bit.png\n",
            "/content/drive/My Drive/citysmall/leftImg8bit/val/lindau/lindau_000026_000019_leftImg8bit.png\n",
            "/content/drive/My Drive/citysmall/leftImg8bit/val/lindau/lindau_000007_000019_leftImg8bit.png\n",
            "/content/drive/My Drive/citysmall/leftImg8bit/val/lindau/lindau_000042_000019_leftImg8bit.png\n",
            "/content/drive/My Drive/citysmall/leftImg8bit/val/lindau/lindau_000047_000019_leftImg8bit.png\n",
            "/content/drive/My Drive/citysmall/leftImg8bit/val/lindau/lindau_000046_000019_leftImg8bit.png\n",
            "/content/drive/My Drive/citysmall/leftImg8bit/val/lindau/lindau_000010_000019_leftImg8bit.png\n",
            "/content/drive/My Drive/citysmall/leftImg8bit/val/lindau/lindau_000009_000019_leftImg8bit.png\n",
            "/content/drive/My Drive/citysmall/leftImg8bit/val/lindau/lindau_000055_000019_leftImg8bit.png\n",
            "/content/drive/My Drive/citysmall/leftImg8bit/val/lindau/lindau_000018_000019_leftImg8bit.png\n",
            "/content/drive/My Drive/citysmall/leftImg8bit/val/lindau/lindau_000006_000019_leftImg8bit.png\n",
            "/content/drive/My Drive/citysmall/leftImg8bit/val/lindau/lindau_000034_000019_leftImg8bit.png\n",
            "/content/drive/My Drive/citysmall/leftImg8bit/val/lindau/lindau_000041_000019_leftImg8bit.png\n",
            "/content/drive/My Drive/citysmall/leftImg8bit/val/lindau/lindau_000038_000019_leftImg8bit.png\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}