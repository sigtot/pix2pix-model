{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  },
  "colab": {
   "name": "Copy of mask_to_city.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "cPZjipS7kUoK",
    "colab_type": "code",
    "outputId": "5e82398e-4430-4a99-81f3-ec01b50cff78",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "! git clone https://github.com/sigtot/unet-auto unet"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "fatal: destination path 'unet' already exists and is not an empty directory.\r\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "H8v8t4c1_VKN",
    "colab_type": "code",
    "outputId": "62e00e5b-0a5b-41ec-c9ba-aba74b473dbe",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "! git -C /content/unet checkout dev"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "fatal: cannot change to '/content/unet': No such file or directory\r\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lNPmdDPHn8SF",
    "colab_type": "code",
    "outputId": "b2a12754-74a7-4d73-dd32-e0b2b97f526b",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "! git -C /content/unet pull"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "fatal: cannot change to '/content/unet': No such file or directory\r\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qx21JWORA3Lg",
    "colab_type": "text"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "81eAI7tNpIc9",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "outputId": "dd53a303-d963-4d58-9044-e46ba440b5f4",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b80391d2b2cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ],
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "id": "PhxokDPckLxb",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import Cityscapes\n",
    "from torchvision.utils import save_image\n",
    "from unet import PavelNet\n",
    "from unet import SigurdModel\n",
    "import datetime"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "id": "VJiWslqnkLxo",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# set device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# make a folder to save output images\n",
    "if not os.path.exists('./mlp_img'):\n",
    "    os.mkdir('./mlp_img')\n",
    "    \n",
    "\n",
    "# a function used to transform numpy array to image format\n",
    "def to_img(x):\n",
    "    x = 0.5 * (x + 1)\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), x.size(1), x.size(2), x.size(3))\n",
    "    return x\n",
    "\n",
    "#################### select your hyperparameters ############################\n",
    "num_epochs = 200\n",
    "batch_size = 10\n",
    "n_samples = 10\n",
    "\n",
    "####### define image transforms, you can have other choices, explore it! #####\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# download dataset\n",
    "# dataset_folder = '/content/drive/My Drive/citysmall'\n",
    "dataset_folder = './data/cityscapes'\n",
    "dataset = Cityscapes(dataset_folder, transform=transform, target_transform=transform, target_type='color')\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, pin_memory=True)"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "id": "7XSotqjIkLxw",
    "colab_type": "code",
    "outputId": "54504f14-2418-402e-dbd5-3bd2d3eb7529",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "model = SigurdModel()\n",
    "model.to(device)"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "SigurdModel(\n  (discriminator): ArtNet(\n    (model): Sequential(\n      (0): Conv2d(6, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n      (2): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n      )\n      (3): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n      )\n      (4): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n      )\n      (5): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n    )\n  )\n  (generator): PavelNet(\n    (e1): EncodeModule(\n      (layers): Sequential(\n        (conv): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n        (relu): LeakyReLU(negative_slope=0.2, inplace=True)\n      )\n    )\n    (e2): EncodeModule(\n      (layers): Sequential(\n        (conv): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): LeakyReLU(negative_slope=0.2, inplace=True)\n      )\n    )\n    (e3): EncodeModule(\n      (layers): Sequential(\n        (conv): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): LeakyReLU(negative_slope=0.2, inplace=True)\n      )\n    )\n    (e4): EncodeModule(\n      (layers): Sequential(\n        (conv): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): LeakyReLU(negative_slope=0.2, inplace=True)\n      )\n    )\n    (e5): EncodeModule(\n      (layers): Sequential(\n        (conv): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): LeakyReLU(negative_slope=0.2, inplace=True)\n      )\n    )\n    (e6): EncodeModule(\n      (layers): Sequential(\n        (conv): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): LeakyReLU(negative_slope=0.2, inplace=True)\n      )\n    )\n    (e7): EncodeModule(\n      (layers): Sequential(\n        (conv): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): LeakyReLU(negative_slope=0.2, inplace=True)\n      )\n    )\n    (e8): EncodeModule(\n      (layers): Sequential(\n        (conv): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n        (relu): LeakyReLU(negative_slope=0.2, inplace=True)\n      )\n    )\n    (d1): DecodeModule(\n      (up): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2))\n      (layers): Sequential(\n        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (do): Dropout2d(p=0.5, inplace=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (d2): DecodeModule(\n      (up): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2))\n      (layers): Sequential(\n        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (do): Dropout2d(p=0.5, inplace=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (d3): DecodeModule(\n      (up): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2))\n      (layers): Sequential(\n        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (do): Dropout2d(p=0.5, inplace=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (d4): DecodeModule(\n      (up): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2))\n      (layers): Sequential(\n        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (d5): DecodeModule(\n      (up): ConvTranspose2d(1024, 256, kernel_size=(4, 4), stride=(2, 2))\n      (layers): Sequential(\n        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (d6): DecodeModule(\n      (up): ConvTranspose2d(512, 128, kernel_size=(4, 4), stride=(2, 2))\n      (layers): Sequential(\n        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (d7): DecodeModule(\n      (up): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2))\n      (layers): Sequential(\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (out): Sequential(\n      (0): ConvTranspose2d(128, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n      (1): Tanh()\n    )\n  )\n  (loss): MSELoss()\n)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 3
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BA904c_r5068",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "model_save_path = \"/content/drive/My Drive/models/model.pt\""
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Cv3rPf3R5ruE",
    "colab_type": "code",
    "outputId": "bbe88b72-2e87-46b2-849e-3723f56f4b46",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "refresh_model = True\n",
    "if os.path.isfile(model_save_path) and not refresh_model:\n",
    "    checkpoint = torch.load(model_save_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    print(f\"Loaded {start_epoch + 1} epochs from file\")\n",
    "else:\n",
    "    start_epoch = 0\n",
    "    print(\"Starting with a fresh model\")"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Starting with a fresh model\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "1xATd-FxkLx4",
    "colab_type": "code",
    "outputId": "7cd77bee-a098-4045-c6d0-6a4ad501ec22",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    }
   },
   "source": [
    "for epoch in range(start_epoch, num_epochs):\n",
    "    for i, data in enumerate(dataloader):\n",
    "        if i > n_samples:\n",
    "            break\n",
    "        img, mask_with_alpha = data\n",
    "        mask = mask_with_alpha[:, :3, :, :]\n",
    "        img = img.to(device)\n",
    "        mask = mask.to(device)\n",
    "        #img = img.view(img.size(0), -1)\n",
    "        \n",
    "        img_pred = model.forward(mask, img)\n",
    "        loss = model.backward()\n",
    "    # ===================user interaction========================\n",
    "    print('epoch [{}/{}], loss:{:.4f}'.format(epoch + 1, num_epochs, loss))\n",
    "    if epoch % 1 == 0:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss\n",
    "            }, model_save_path)\n",
    "\n",
    "        pic = to_img(img_pred.data)\n",
    "        save_image(pic, './mlp_img/image_{}.png'.format(epoch))\n",
    "        \n",
    "        ori_pic = to_img(img.data)\n",
    "        save_image(ori_pic, './mlp_img/ori_image_{}.png'.format(epoch))\n",
    "        \n",
    "        mask_pic = to_img(mask.data)\n",
    "        save_image(mask_pic, './mlp_img/mask_image_{}.png'.format(epoch))\n"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6f77da976ffe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mimg_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# ===================backward====================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;31m# ===================user interaction========================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch [{}/{}], loss:{:.4f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DL/unet-auto/unet/sigurd_model.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mloss_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DL/env/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DL/env/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time."
     ],
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time.",
     "output_type": "error"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "-MWqV5HtkLyA",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}